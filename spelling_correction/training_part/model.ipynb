{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        # Load the data\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Preprocess the dataset to remove rows where correct_word or incorrect_word are not strings\n",
    "        self.data = self.data[self.data['Correct Word'].apply(lambda x: isinstance(x, str))]\n",
    "        self.data = self.data[self.data['Incorrect Word'].apply(lambda x: isinstance(x, str))]\n",
    "        \n",
    "        # Vocabulary setup\n",
    "        self.vocab = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "        self.vocab_size = len(self.vocab) + 1\n",
    "        self.ctoi = {char: idx for idx, char in enumerate(self.vocab)}\n",
    "        \n",
    "        # One-Hot Encoding\n",
    "        self.create_OHE()\n",
    "\n",
    "    def create_OHE(self):\n",
    "        \"\"\"Creates a One-Hot Encoding matrix for the vocabulary.\"\"\"\n",
    "        self.OHE = torch.zeros((self.vocab_size, self.vocab_size))\n",
    "        for i in range(self.vocab_size):\n",
    "            self.OHE[i, i] = 1\n",
    "\n",
    "    def get_OHE(self, word):\n",
    "        \"\"\"Converts a word into a one-hot encoding tensor.\"\"\"\n",
    "        emb = [self.OHE[self.ctoi.get(char, self.vocab_size - 1)] for char in word]\n",
    "        return torch.stack(emb)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns (correct_word, incorrect_word, target) as tensors.\"\"\"\n",
    "        correct_word = self.data.iloc[idx, 0].lower()\n",
    "        incorrect_word = self.data.iloc[idx, 1].lower()\n",
    "        target = torch.tensor([self.data.iloc[idx, 2]], dtype=torch.float32)\n",
    "        return self.get_OHE(correct_word), self.get_OHE(incorrect_word), target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Pads sequences in a batch to the max length in the batch.\"\"\"\n",
    "    corrects, incorrects, targets = zip(*batch)\n",
    "    \n",
    "    max_len = max(max(c.shape[0] for c in corrects), max(i.shape[0] for i in incorrects))\n",
    "\n",
    "    pad_tensor = torch.zeros((max_len, corrects[0].shape[1]))  # (max_len, vocab_size)\n",
    "    \n",
    "    corrects_padded = [torch.cat((c, pad_tensor[:max_len - c.shape[0]]), dim=0) for c in corrects]\n",
    "    incorrects_padded = [torch.cat((i, pad_tensor[:max_len - i.shape[0]]), dim=0) for i in incorrects]\n",
    "    \n",
    "    return torch.stack(corrects_padded), torch.stack(incorrects_padded), torch.stack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, vocab_size=27, emb_dim=300, num_epochs=15, lr=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "        self.vocab_size = len(self.vocab) + 1\n",
    "        self.ctoi = {char: idx for idx, char in enumerate(self.vocab)}\n",
    "\n",
    "        self.num_epochs = num_epochs\n",
    "        self.vocab_size = vocab_size\n",
    "        self.lstm1 = nn.LSTM(input_size=self.vocab_size, hidden_size=emb_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=emb_dim, hidden_size=emb_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "\n",
    "        self.loss_fn = nn.L1Loss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)  \n",
    "\n",
    "        self.create_OHE()\n",
    "\n",
    "    def create_OHE(self):\n",
    "        \"\"\"Creates a One-Hot Encoding matrix for the vocabulary.\"\"\"\n",
    "        self.OHE = torch.zeros((self.vocab_size, self.vocab_size))\n",
    "        for i in range(self.vocab_size):\n",
    "            self.OHE[i, i] = 1\n",
    "\n",
    "    def get_OHE(self, word):\n",
    "        \"\"\"Converts a word into a one-hot encoding tensor.\"\"\"\n",
    "        emb = [self.OHE[self.ctoi.get(char, self.vocab_size - 1)] for char in word]\n",
    "        return torch.stack(emb)\n",
    "    \n",
    "    def fit(self, batched_data, save_path=\"./saved_model_3\"):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            start_time = time.time()\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "            for x1, x2, target_batch in batched_data:\n",
    "                x1, x2, target_batch = x1.to(self.device), x2.to(self.device), target_batch.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.forward(x1, x2)\n",
    "                loss = self.loss_fn(outputs, target_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "            avg_time_per_batch = epoch_time / len(batched_data)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.num_epochs} - Loss: {epoch_loss / len(batched_data)} - Time: {epoch_time:.2f}s (Avg per batch: {avg_time_per_batch:.2f}s)\")\n",
    "            \n",
    "            model_filename = f\"{save_path}/model{epoch+1}.pth\"\n",
    "            self.save_model(model_filename)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        out1, _ = self.lstm1(x)\n",
    "        out2, (hn, _) = self.lstm2(out1)\n",
    "        return hn.squeeze(0) \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        emb1 = self.get_embedding(x1)\n",
    "        emb2 = self.get_embedding(x2)\n",
    "\n",
    "        diff = emb1 - emb2\n",
    "        squared_norm = torch.sum(diff ** 2, dim=1, keepdim=True)\n",
    "\n",
    "        out = torch.sigmoid(self.fc(squared_norm))\n",
    "        return out\n",
    "    \n",
    "    def save_model(self, model_name):\n",
    "        torch.save(self.state_dict(), model_name)\n",
    "        print(f\"Model saved to {model_name}\")\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        self.load_state_dict(torch.load(model_name))\n",
    "        self.eval()  # Set the model to evaluation mode after loading\n",
    "        print(f\"Model loaded from {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./datasets/Specific Combinations.csv\"\n",
    "\n",
    "dataset = WordDataset(csv_path)  \n",
    "batch_size = 128\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for correct_batch, incorrect_batch, target_batch in dataloader:\n",
    "    print(f\"Correct words batch shape: {correct_batch.shape}\")  \n",
    "    print(f\"Incorrect words batch shape: {incorrect_batch.shape}\")  \n",
    "    print(f\"Target batch shape: {target_batch.shape}\")  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel()\n",
    "model.fit(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"./saved_model_3/char2vec.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = CustomModel() \n",
    "loaded_model.load_model(\"./saved_model_3/char2vec.pth\")\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words = ['input', 'clumsy', 'giraffe',\"ion\"]\n",
    "incorrect_words = ['inpt', 'girafee', 'clumssy', 'fgiraffe', 'lumsy', \"intup\",\"lion\",]\n",
    "\n",
    "correct_embeddings = [loaded_model.get_embedding(loaded_model.get_OHE(word).to(model.device)) for word in correct_words]\n",
    "incorrect_embeddings = [loaded_model.get_embedding(loaded_model.get_OHE(word).to(model.device)) for word in incorrect_words]\n",
    "\n",
    "all_embeddings = correct_embeddings + incorrect_embeddings\n",
    "\n",
    "flattened_embeddings = [emb.flatten().cpu().detach().numpy() for emb in all_embeddings]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(flattened_embeddings)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, (word, color) in enumerate(zip(correct_words + incorrect_words, ['green'] * len(correct_words) + ['black'] * len(incorrect_words))):\n",
    "    plt.scatter(pca_result[i, 0], pca_result[i, 1], color=color)\n",
    "    plt.text(pca_result[i, 0] + 0.02, pca_result[i, 1] + 0.02, word, color=color)\n",
    "\n",
    "plt.title(\"PCA visualization of correct and incorrect spellings\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
